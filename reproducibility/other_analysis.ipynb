{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other analysis scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = './files/csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity between Headless and Native for sites that have more Rejected > Accepted: 0.25925925925925924\n",
      "{'https://bmj.com', 'https://match.com', 'https://cancer.org', 'https://amplitude.com', 'https://worldcat.org', 'https://avg.com', 'https://rackspacecloud.com'}\n",
      "Jaccard Similarity between Headless and Native for sites that have more Rejected > No Interaction: 0.6394557823129252\n",
      "{'https://mastercard.com', 'https://ccleaner.com', 'https://king.com', 'https://adtelligent.com', 'https://agora.io', 'https://pubnub.com', 'https://deltadna.net', 'https://sendinblue.com', 'https://eagleeyenetworks.com', 'https://siteground.us', 'https://mimecast.net', 'https://watchguard.com', 'https://tfl.gov.uk', 'https://snowflake.com', 'https://premierleague.com', 'https://iubenda.com', 'https://pb.com', 'https://doodle.com', 'https://thelancet.com', 'https://pandasecurity.com', 'https://swrve.com', 'https://smartthings.com', 'https://ultradns.com', 'https://gumgum.com', 'https://symantec.com', 'https://esa.int', 'https://epam.com', 'https://mendeley.com', 'https://greenhouse.io', 'https://rackspacecloud.com', 'https://narvar.com', 'https://comodo.com', 'https://flashscore.com', 'https://rioseo.com', 'https://hp.com', 'https://vertamedia.com', 'https://fifa.com', 'https://freepik.es', 'https://superuser.com', 'https://playrix.com', 'https://oclc.org', 'https://docker.com', 'https://serverfault.com', 'https://kaltura.com', 'https://aliyun.com', 'https://avg.com', 'https://justpremium.com', 'https://surveymonkey.com', 'https://barracudanetworks.com', 'https://imperial.ac.uk', 'https://bmj.com', 'https://verisign.com', 'https://cancer.org', 'https://urbanairship.com', 'https://askubuntu.com', 'https://nap.edu', 'https://viber.com', 'https://elsevierhealth.com', 'https://seagate.com', 'https://mitre.org', 'https://zend.com', 'https://ssrn.com', 'https://ey.com', 'https://siteground.com', 'https://nationalarchives.gov.uk', 'https://esri.com', 'https://match.com', 'https://digicert.com', 'https://helpshift.com', 'https://trustarc.com', 'https://worldcat.org', 'https://osu.edu', 'https://lnk.to', 'https://cell.com', 'https://plos.org', 'https://nvidia.com', 'https://senderscore.com', 'https://geotrust.com', 'https://technologyreview.com', 'https://teads.tv', 'https://wufoo.com', 'https://isipp.com', 'https://eurogamer.net', 'https://imgsmail.ru', 'https://dxc.com', 'https://truste.com', 'https://broadcom.com', 'https://mynavi.jp', 'https://businesswire.com', 'https://kcl.ac.uk', 'https://gmu.edu', 'https://algolianet.com', 'https://apptimize.com', 'https://exoclick.com'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def compute_jaccard_similarity(file1, file2):\n",
    "    \"\"\"\n",
    "    Check similarity between keys of two CSV files\n",
    "    \"\"\"\n",
    "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "        reader1 = csv.reader(f1)\n",
    "        reader2 = csv.reader(f2)\n",
    "        \n",
    "        # Skip the headers\n",
    "        next(reader1)\n",
    "        next(reader2)\n",
    "        \n",
    "        # Read the first columns from both files\n",
    "        column1 = [row[0] for row in reader1]\n",
    "        column2 = [row[0] for row in reader2]\n",
    "        \n",
    "        # Compute Jaccard Similarity\n",
    "        # i.e., intersection / union\n",
    "        similarity = len(set(column1) & set(column2)) / len(set(column1) | set(column2))\n",
    "        \n",
    "        return similarity\n",
    "    \n",
    "def get_intersection(file1, file2):\n",
    "    \"\"\"\n",
    "    Get intersection between keys of two CSV files\n",
    "    \"\"\"\n",
    "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "        reader1 = csv.reader(f1)\n",
    "        reader2 = csv.reader(f2)\n",
    "\n",
    "        # Skip the headers\n",
    "        next(reader1)\n",
    "        next(reader2)\n",
    "        \n",
    "        # Read the first columns from both files\n",
    "        column1 = [row[0] for row in reader1]\n",
    "        column2 = [row[0] for row in reader2]\n",
    "\n",
    "        return set(column1) & set(column2)\n",
    "\n",
    "\n",
    "# Rejected > Accepted\n",
    "file1_path = CSV_DIR + '/headless_more_rejected_than_accepted.csv'\n",
    "file2_path = CSV_DIR + '/native_more_rejected_than_accepted.csv'\n",
    "similarity_score = compute_jaccard_similarity(file1_path, file2_path)\n",
    "print(f\"Jaccard Similarity between Headless and Native for sites that have more Rejected > Accepted: {similarity_score}\")\n",
    "print(get_intersection(file1_path, file2_path))\n",
    "\n",
    "# Rejected > No Interaction\n",
    "file1_path = CSV_DIR + '/headless_more_rejected_than_no_interaction.csv'\n",
    "file2_path = CSV_DIR + '/native_more_rejected_than_no_interaction.csv'\n",
    "similarity_score = compute_jaccard_similarity(file1_path, file2_path)\n",
    "print(f\"Jaccard Similarity between Headless and Native for sites that have more Rejected > No Interaction: {similarity_score}\")\n",
    "print(get_intersection(file1_path, file2_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrepancy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cookies_from_har(file, url):\n",
    "    \"\"\"\n",
    "    Returns a list of cookies from an HAR file.\n",
    "\n",
    "    The HAR file should be generated using Chrome DevTools.\n",
    "    `file` is the path to the HAR file.\n",
    "    `url` is the URL of the website which the HAR was extracted from.\n",
    "    \"\"\"\n",
    "\n",
    "    data = json.load(open(file, 'r'))\n",
    "    for entry in data['log']['entries']:\n",
    "        request = entry['request']\n",
    "        if request['method'] == 'GET' and request['url'] == url:\n",
    "            return request['cookies']\n",
    "\n",
    "har_cookies = get_cookies_from_har('./files/har/www.bmj.com.har', 'https://www.bmj.com/')\n",
    "\n",
    "def get_cookies_from_csv(file):\n",
    "    \"\"\"\n",
    "    Returns a list of cookies from a CSV file.\n",
    "\n",
    "    The CSV file should be generated using `get_cookies` in `analysis.ipynb`.\n",
    "    `file` is the path to the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    cookies = []\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    for index, cookie in df.iterrows():\n",
    "        cookies.append({\n",
    "            'name': cookie['name'],\n",
    "            'domain': cookie['host'],\n",
    "            # 'value': cookie['value'] # TODO: Add values\n",
    "        })\n",
    "\n",
    "    return cookies\n",
    "\n",
    "bannerclick_cookies = get_cookies_from_csv('./files/csv/bmj.com_accept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('www.bmj.com', 'dmd-signal-112-497-382A7D95-21fabb8c-b6b7-47c7-aa07-d50b34b9096d')\n",
      "('.bmj.com', 'zps-tgr-dts')\n",
      "('www.bmj.com', 'ln_or')\n",
      "('.bmj.com', 'loggedIn')\n",
      "('.bmj.com', '_ga_LHT0ZJKRSY')\n",
      "('www.bmj.com', 'dmd-vid')\n",
      "('.bmj.com', 'wisepops')\n",
      "('.bmj.com', '_fbp')\n",
      "('.bmj.com', 'wisepops_session')\n",
      "('.bmj.com', '_gat_UA-432960-5')\n",
      "('.bmj.com', 'zsc080ab08721924c07a116c8a1a078f0f0')\n",
      "('www.bmj.com', 'dmd-sid')\n",
      "('.bmj.com', 'OptanonConsent')\n",
      "('www.bmj.com', '_sess')\n",
      "('.bmj.com', 'zft-sdc')\n",
      "('.bmj.com', 'FPLC')\n",
      "('.bmj.com', '_gid')\n",
      "('.bmj.com', 'FPID')\n",
      "('.bmj.com', '_ga')\n",
      "('.bmj.com', 'RefTrackGroup')\n",
      "('.bmj.com', 'wisepops_visits')\n",
      "('www.bmj.com', 'zabUserId')\n",
      "('.bmj.com', 'RefTrack')\n",
      "('.bmj.com', '_ga_8P7810XE1M')\n",
      "('www.bmj.com', 'dmd-ahk')\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def compute_cookie_similarity(cookies1, cookies2):\n",
    "    \"\"\"\n",
    "    Check similarity between two cookie lists.\n",
    "\n",
    "    The lists must be dictionaries with keys 'domain' and 'name'.\n",
    "    \"\"\"\n",
    "\n",
    "    cookies1 = [(cookie['domain'], cookie['name']) for cookie in cookies1]\n",
    "    cookies2 = [(cookie['domain'], cookie['name']) for cookie in cookies2]\n",
    "\n",
    "    for cookie in cookies1_set:\n",
    "        print(cookie)\n",
    "\n",
    "    similarity = len(cookies1_set & cookies2_set) / len(cookies1_set | cookies2_set)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "similarity = compute_cookie_similarity(har_cookies, bannerclick_cookies)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
